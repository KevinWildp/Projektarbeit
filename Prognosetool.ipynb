{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a47eea6",
   "metadata": {},
   "source": [
    "# Import Liberaies / and scrape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5435139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soccerdata as sd\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, deque # new\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    " \n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "339ca350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/21/24 09:52:16] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving cached data to <span style=\"color: #800080; text-decoration-color: #800080\">/Users/kevinwildprett/soccerdata/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">MatchHistory</span> <a href=\"file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_common.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py#89\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">89</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/21/24 09:52:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving cached data to \u001b[35m/Users/kevinwildprett/soccerdata/data/\u001b[0m\u001b[95mMatchHistory\u001b[0m \u001b]8;id=351662;file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py\u001b\\\u001b[2m_common.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=503062;file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py#89\u001b\\\u001b[2m89\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving cached data to <span style=\"color: #800080; text-decoration-color: #800080\">/Users/kevinwildprett/soccerdata/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">MatchHistory</span> <a href=\"file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_common.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py#89\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">89</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving cached data to \u001b[35m/Users/kevinwildprett/soccerdata/data/\u001b[0m\u001b[95mMatchHistory\u001b[0m \u001b]8;id=319330;file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py\u001b\\\u001b[2m_common.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=558123;file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py#89\u001b\\\u001b[2m89\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scraper class instance for  for the 2020/21 & 2021/22\n",
    "mh = sd.MatchHistory(leagues=['GER-Bundesliga'], seasons=['2020-2021'])\n",
    "mh2= sd.MatchHistory(leagues=['GER-Bundesliga'], seasons=['2021-2022'])\n",
    "# Get match data of each team\n",
    "match_stats= mh.read_games()\n",
    "test_data = mh2.read_games()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bf280f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MultiIndex into regular one\n",
    "match_stats = match_stats.reset_index()\n",
    "match_stats.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_data = test_data.reset_index()\n",
    "test_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566342c",
   "metadata": {},
   "source": [
    "new dataframe for prev season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "46a452e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "team = ['Bayern Munich', 'Dortmund', 'RB Leipzig', 'Leverkusen', \"M\\'gladbach\", 'Ein Frankfurt', 'Wolfsburg', 'Hertha', 'Hoffenheim', 'Stuttgart', 'Mainz', 'Freiburg', 'Schalke 04', 'FC Koln', 'Werder Bremen', 'Augsburg', 'Union Berlin', 'Bielefeld']\n",
    "\n",
    "total_values = ['858.23', '628.40', '574.95', '373.25', '300.75', '269.15', '256.83', '228.88', '228.15', '189.25', '163.30', '139.10', '123.05', '118.20', '111.98', '93.05', '82.05', '56.73']\n",
    "\n",
    "\n",
    "# create dataframe\n",
    "df_teams = pd.DataFrame({\n",
    "    'team': team,\n",
    "    'total_values': total_values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad017581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge for home_market_value\n",
    "match_stats = pd.merge(match_stats,  df_teams[['team', 'total_values']], left_on='home_team', right_on='team').rename(columns={'total_values': 'home_value'})\n",
    "match_stats = match_stats.drop(columns=['team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b68da4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge for away_market_value\n",
    "match_stats = pd.merge(match_stats,  df_teams[['team', 'total_values']], left_on='away_team', right_on='team').rename(columns={'total_values': 'away_value'})\n",
    "match_stats = match_stats.drop(columns=['team'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7eaa2",
   "metadata": {},
   "source": [
    "new dataframe for test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "265f205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "team = ['Bayern Munich', 'Dortmund', 'RB Leipzig', 'Leverkusen', 'Wolfsburg', \"M\\'gladbach\", 'Ein Frankfurt', 'Hoffenheim', 'Freiburg', 'Stuttgart', 'Hertha', 'Mainz', 'Union Berlin', 'FC Koln', 'Augsburg', 'Bielefeld', 'Bochum', 'Greuther Furth']\n",
    "\n",
    "total_values = ['790.33', '558.98', '499.95', '455.05', '269.20', '236.80', '228.15', '211.43', '176.35', '174.23', '155.78', '131.03', '115.90', '99.28', '95.30', '65.85', '52.25', '36.95']\n",
    "\n",
    "# create dataframe\n",
    "df_teams2 = pd.DataFrame({\n",
    "    'team': team,\n",
    "    'total_values': total_values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ceab95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge for home_market_value\n",
    "test_data = pd.merge(test_data,  df_teams2[['team', 'total_values']], left_on='home_team', right_on='team').rename(columns={'total_values': 'home_value'})\n",
    "test_data = test_data.drop(columns=['team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cbbe4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge for away_market_value\n",
    "test_data = pd.merge(test_data,  df_teams2[['team', 'total_values']], left_on='away_team', right_on='team').rename(columns={'total_values': 'away_value'})\n",
    "test_data = test_data.drop(columns=['team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6e5498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_stats = match_stats.sort_values(by='date').reset_index(drop=True)\n",
    "test_data = test_data.sort_values(by='date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54d09e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['league', 'season', 'game', 'date', 'home_team', 'away_team',\n",
       "       'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG', 'HTR', 'HS', 'AS', 'HST',\n",
       "       'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR', 'B365H',\n",
       "       'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'PSH',\n",
       "       'PSD', 'PSA', 'WHH', 'WHD', 'WHA', 'VCH', 'VCD', 'VCA', 'MaxH',\n",
       "       'MaxD', 'MaxA', 'AvgH', 'AvgD', 'AvgA', 'B365>2.5', 'B365<2.5',\n",
       "       'P>2.5', 'P<2.5', 'Max>2.5', 'Max<2.5', 'Avg>2.5', 'Avg<2.5',\n",
       "       'AHh', 'B365AHH', 'B365AHA', 'PAHH', 'PAHA', 'MaxAHH', 'MaxAHA',\n",
       "       'AvgAHH', 'AvgAHA', 'B365CH', 'B365CD', 'B365CA', 'BWCH', 'BWCD',\n",
       "       'BWCA', 'IWCH', 'IWCD', 'IWCA', 'PSCH', 'PSCD', 'PSCA', 'WHCH',\n",
       "       'WHCD', 'WHCA', 'VCCH', 'VCCD', 'VCCA', 'MaxCH', 'MaxCD', 'MaxCA',\n",
       "       'AvgCH', 'AvgCD', 'AvgCA', 'B365C>2.5', 'B365C<2.5', 'PC>2.5',\n",
       "       'PC<2.5', 'MaxC>2.5', 'MaxC<2.5', 'AvgC>2.5', 'AvgC<2.5', 'AHCh',\n",
       "       'B365CAHH', 'B365CAHA', 'PCAHH', 'PCAHA', 'MaxCAHH', 'MaxCAHA',\n",
       "       'AvgCAHH', 'AvgCAHA', 'home_value', 'away_value'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_stats.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a5fc4f",
   "metadata": {},
   "source": [
    "# Bulding new Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1449be",
   "metadata": {},
   "source": [
    "Matchdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aff0b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate matchdays for each team\n",
    "def update_matchday(row,team_matchday_counts):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Increment matchday count for home and away teams\n",
    "    team_matchday_counts[home_team] += 1\n",
    "    team_matchday_counts[away_team] += 1\n",
    "    \n",
    "    # Assign matchday counts to the row\n",
    "    row['home_team_matchday'] = team_matchday_counts[home_team]\n",
    "    row['away_team_matchday'] = team_matchday_counts[away_team]\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f825c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_matchday_counts_df1 = defaultdict(int)\n",
    "match_stats = match_stats.apply(lambda row: update_matchday(row, team_matchday_counts_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_matchday_counts_df2 = defaultdict(int)\n",
    "test_data = test_data.apply(lambda row: update_matchday(row, team_matchday_counts_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749c3884",
   "metadata": {},
   "source": [
    "Cumulative Points (positiv effect on pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "730d7f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update cumulative points for each team\n",
    "def update_cumulative_points(row, team_points):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    home_matchday = row['home_team_matchday']\n",
    "    away_matchday = row['away_team_matchday']\n",
    "    \n",
    "    # Initialize cumulative points as 0 for the first matchday\n",
    "    if home_matchday == 1:\n",
    "        row['home_cumulative_points'] = 0\n",
    "    else:\n",
    "        row['home_cumulative_points'] = team_points[home_team]\n",
    "    \n",
    "    if away_matchday == 1:\n",
    "        row['away_cumulative_points'] = 0\n",
    "    else:\n",
    "        row['away_cumulative_points'] = team_points[away_team]\n",
    "    \n",
    "    # Update points based on match result (add to history after setting current cumulative points)\n",
    "    if row['FTR'] == 'H':  # Home team wins\n",
    "        team_points[home_team] += 3  # 3 points for home team\n",
    "        team_points[away_team] += 0  # 0 points for away team\n",
    "    elif row['FTR'] == 'A':  # Away team wins\n",
    "        team_points[home_team] += 0  # 0 points for home team\n",
    "        team_points[away_team] += 3  # 3 points for away team\n",
    "    else:  # Draw\n",
    "        team_points[home_team] += 1  # 1 point for home team\n",
    "        team_points[away_team] += 1  # 1 point for away team\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "333143f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_points_df1 = defaultdict(int)\n",
    "match_stats = match_stats.apply(lambda row: update_cumulative_points(row, team_points_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_points_df2 = defaultdict(int)\n",
    "test_data = test_data.apply(lambda row: update_cumulative_points(row, team_points_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc1b8",
   "metadata": {},
   "source": [
    "Wins in last 5 matchdays (negative effect on pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb498ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the last 5 match history and count wins\n",
    "def update_last_5_wins(row, team_last_5_results):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Calculate the number of wins in the last 5 matches or fewer if not enough matches have been played\n",
    "    row['home_last_5_wins'] = sum(team_last_5_results[home_team])\n",
    "    row['away_last_5_wins'] = sum(team_last_5_results[away_team])\n",
    "    \n",
    "    # Add current match result to history (after calculation)\n",
    "    if row['FTR'] == 'H':  # Home team wins\n",
    "        team_last_5_results[home_team].append(1)\n",
    "        team_last_5_results[away_team].append(0)\n",
    "    elif row['FTR'] == 'A':  # Away team wins\n",
    "        team_last_5_results[home_team].append(0)\n",
    "        team_last_5_results[away_team].append(1)\n",
    "    else:  # Draw\n",
    "        team_last_5_results[home_team].append(0)\n",
    "        team_last_5_results[away_team].append(0)\n",
    "    \n",
    "    return row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30a36ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_last_5_results_df1 = defaultdict(lambda: deque(maxlen=5))\n",
    "match_stats = match_stats.apply(lambda row: update_last_5_wins(row, team_last_5_results_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_last_5_results_df2 = defaultdict(lambda: deque(maxlen=5))\n",
    "test_data = test_data.apply(lambda row: update_last_5_wins(row, team_last_5_results_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c49388f",
   "metadata": {},
   "source": [
    "Shots on Goal (negative effect on pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7724f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the number of shots on target for each team in the last 5 matches\n",
    "def update_last_5_shots(row, team_last_5_shots):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Calculate the total shots on target in the last 5 matches or fewer if not enough matches have been played\n",
    "    row['home_last_5_shots'] = sum(team_last_5_shots[home_team])\n",
    "    row['away_last_5_shots'] = sum(team_last_5_shots[away_team])\n",
    "    \n",
    "    # Add current match shots on target to history\n",
    "    team_last_5_shots[home_team].append(row['HST'])  # Home shots on target\n",
    "    team_last_5_shots[away_team].append(row['AST'])  # Away shots on target\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8fc06c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_last_5_shots_df1 = defaultdict(lambda: deque(maxlen=5))\n",
    "match_stats = match_stats.apply(lambda row: update_last_5_shots(row, team_last_5_shots_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_last_5_shots_df2 = defaultdict(lambda: deque(maxlen=5))\n",
    "test_data = test_data.apply(lambda row: update_last_5_shots(row, team_last_5_shots_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612013b0",
   "metadata": {},
   "source": [
    "Goaldifference (possitive effect on pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1a7be4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the goal difference for each team in the last 5 matches\n",
    "def update_last_5_goal_diff(row, team_last_5_goal_diff):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Calculate the current match goal difference\n",
    "    home_goal_diff = row['FTHG'] - row['FTAG']\n",
    "    away_goal_diff = -home_goal_diff  # Invert for the away team\n",
    "\n",
    "    # Calculate the total goal difference in the last 5 matches or fewer if not enough matches have been played\n",
    "    row['home_last_5_goal_diff'] = sum(team_last_5_goal_diff[home_team])\n",
    "    row['away_last_5_goal_diff'] = sum(team_last_5_goal_diff[away_team])\n",
    "    \n",
    "    # Add current match goal difference to history\n",
    "    team_last_5_goal_diff[home_team].append(home_goal_diff)\n",
    "    team_last_5_goal_diff[away_team].append(away_goal_diff)\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e6e6ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_last_5_goal_diff_df1 = defaultdict(lambda: deque(maxlen=5))\n",
    "match_stats = match_stats.apply(lambda row: update_last_5_goal_diff(row, team_last_5_goal_diff_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_last_5_goal_diff_df2 = defaultdict(lambda: deque(maxlen=5))\n",
    "test_data = test_data.apply(lambda row: update_last_5_goal_diff(row, team_last_5_goal_diff_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe61d8",
   "metadata": {},
   "source": [
    "Amount halftime goals (possitive effect on pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fdf37464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and update the sum of half-time goals for the last 5 matches for each team\n",
    "def calculate_last_5_half_time_goals(row, team_last_5_half_time_goals):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Calculate the sum of half-time goals in the last 5 matches or fewer if not enough matches have been played\n",
    "    row['home_last_5_half_time_goals'] = sum(team_last_5_half_time_goals[home_team])\n",
    "    row['away_last_5_half_time_goals'] = sum(team_last_5_half_time_goals[away_team])\n",
    "    \n",
    "    # Add the current match half-time goals to history\n",
    "    team_last_5_half_time_goals[home_team].append(row['HTHG'])  # Home half-time goals\n",
    "    team_last_5_half_time_goals[away_team].append(row['HTAG'])  # Away half-time goals\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "632ab0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_last_5_half_time_goals_df1 = defaultdict(lambda: deque(maxlen=5))\n",
    "match_stats = match_stats.apply(lambda row: calculate_last_5_half_time_goals(row, team_last_5_half_time_goals_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_last_5_half_time_goals_df2 = defaultdict(lambda: deque(maxlen=5))\n",
    "test_data = test_data.apply(lambda row: calculate_last_5_half_time_goals(row, team_last_5_half_time_goals_df2), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e8e0ef",
   "metadata": {},
   "source": [
    "Corner shots (possitive effect on pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7ec586c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and update the sum of shot corners for the last 5 matches for each team\n",
    "def calculate_last_5_corners_shot(row, team_last_5_corners_shot):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Calculate the sum of Corners in the last 5 matches or fewer if not enough matches have been played\n",
    "    row['home_last_5_corners_shot'] = sum(team_last_5_corners_shot[home_team])\n",
    "    row['away_last_5_corners_shot'] = sum(team_last_5_corners_shot[away_team])\n",
    "    \n",
    "    # Add the current match corners to history\n",
    "    team_last_5_corners_shot[home_team].append(row['HC'])  # Home Corners\n",
    "    team_last_5_corners_shot[away_team].append(row['AC'])  # Away Corners\n",
    "    \n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "699c688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_last_5_corners_shot_df1 = defaultdict(lambda: deque(maxlen=5))\n",
    "match_stats = match_stats.apply(lambda row: calculate_last_5_corners_shot(row, team_last_5_corners_shot_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_last_5_corners_shot_df2 = defaultdict(lambda: deque(maxlen=5))\n",
    "test_data = test_data.apply(lambda row: calculate_last_5_corners_shot(row, team_last_5_corners_shot_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26778443",
   "metadata": {},
   "source": [
    "ELO-Ratings (possitive effect on pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46f3e1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/wh82d8z12pjcn_v99zhyg1t80000gn/T/ipykernel_51557/4152494630.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  match_stats['current_home_elo'] = current_home_elo_list\n",
      "/var/folders/n_/wh82d8z12pjcn_v99zhyg1t80000gn/T/ipykernel_51557/4152494630.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  match_stats['current_away_elo'] = current_away_elo_list\n"
     ]
    }
   ],
   "source": [
    "### for train data ###\n",
    "# Dictionary to keep track of current Elo ratings for each team\n",
    "# Reset Elo ratings and ensure initial value is 1500 for all teams\n",
    "# Re-initialize Elo calculation to ensure correct data\n",
    "team_elo = defaultdict(lambda: 1500)\n",
    "K=32\n",
    "\n",
    "# Lists to store Elo ratings for current matchdays\n",
    "current_home_elo_list = []\n",
    "current_away_elo_list = []\n",
    "\n",
    "# Iterate over each match to calculate Elo ratings correctly\n",
    "for index, row in match_stats.iterrows():\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "\n",
    "    # Get the current Elo ratings from the dictionary\n",
    "    current_home_elo = team_elo[home_team]\n",
    "    current_away_elo = team_elo[away_team]\n",
    "\n",
    "    # Append the current Elo ratings to the lists\n",
    "    current_home_elo_list.append(current_home_elo)\n",
    "    current_away_elo_list.append(current_away_elo)\n",
    "\n",
    "    # Calculate expected outcomes\n",
    "    expected_home = 1 / (1 + 10 ** ((current_away_elo - current_home_elo) / 400))\n",
    "    expected_away = 1 / (1 + 10 ** ((current_home_elo - current_away_elo) / 400))\n",
    "\n",
    "    # Determine actual match outcome\n",
    "    if row['FTHG'] > row['FTAG']:  # Home win\n",
    "        actual_home = 1\n",
    "        actual_away = 0\n",
    "    elif row['FTHG'] < row['FTAG']:  # Away win\n",
    "        actual_home = 0\n",
    "        actual_away = 1\n",
    "    else:  # Draw\n",
    "        actual_home = 0.5\n",
    "        actual_away = 0.5\n",
    "\n",
    "    # Update Elo ratings using the K factor\n",
    "    new_home_elo = current_home_elo + K * (actual_home - expected_home)\n",
    "    new_away_elo = current_away_elo + K * (actual_away - expected_away)\n",
    "\n",
    "    # Update the dictionary with the new Elo ratings for the next match\n",
    "    team_elo[home_team] = new_home_elo\n",
    "    team_elo[away_team] = new_away_elo\n",
    "\n",
    "# Add the current Elo ratings to the DataFrame\n",
    "match_stats['current_home_elo'] = current_home_elo_list\n",
    "match_stats['current_away_elo'] = current_away_elo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "30288501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/wh82d8z12pjcn_v99zhyg1t80000gn/T/ipykernel_51557/1577465140.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data['current_home_elo'] = current_home_elo_list\n",
      "/var/folders/n_/wh82d8z12pjcn_v99zhyg1t80000gn/T/ipykernel_51557/1577465140.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data['current_away_elo'] = current_away_elo_list\n"
     ]
    }
   ],
   "source": [
    "### 4 test data ###\n",
    "# Dictionary to keep track of current Elo ratings for each team\n",
    "# Reset Elo ratings and ensure initial value is 1500 for all teams\n",
    "# Re-initialize Elo calculation to ensure correct data\n",
    "team_elo = defaultdict(lambda: 1500)\n",
    "K=32\n",
    "\n",
    "# Lists to store Elo ratings for current matchdays\n",
    "current_home_elo_list = []\n",
    "current_away_elo_list = []\n",
    "\n",
    "# Iterate over each match to calculate Elo ratings correctly\n",
    "for index, row in test_data.iterrows():\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "\n",
    "    # Get the current Elo ratings from the dictionary\n",
    "    current_home_elo = team_elo[home_team]\n",
    "    current_away_elo = team_elo[away_team]\n",
    "\n",
    "    # Append the current Elo ratings to the lists\n",
    "    current_home_elo_list.append(current_home_elo)\n",
    "    current_away_elo_list.append(current_away_elo)\n",
    "\n",
    "    # Calculate expected outcomes\n",
    "    expected_home = 1 / (1 + 10 ** ((current_away_elo - current_home_elo) / 400))\n",
    "    expected_away = 1 / (1 + 10 ** ((current_home_elo - current_away_elo) / 400))\n",
    "\n",
    "    # Determine actual match outcome\n",
    "    if row['FTHG'] > row['FTAG']:  # Home win\n",
    "        actual_home = 1\n",
    "        actual_away = 0\n",
    "    elif row['FTHG'] < row['FTAG']:  # Away win\n",
    "        actual_home = 0\n",
    "        actual_away = 1\n",
    "    else:  # Draw\n",
    "        actual_home = 0.5\n",
    "        actual_away = 0.5\n",
    "\n",
    "    # Update Elo ratings using the K factor\n",
    "    new_home_elo = current_home_elo + K * (actual_home - expected_home)\n",
    "    new_away_elo = current_away_elo + K * (actual_away - expected_away)\n",
    "\n",
    "    # Update the dictionary with the new Elo ratings for the next match\n",
    "    team_elo[home_team] = new_home_elo\n",
    "    team_elo[away_team] = new_away_elo\n",
    "\n",
    "# Add the current Elo ratings to the DataFrame\n",
    "test_data['current_home_elo'] = current_home_elo_list\n",
    "test_data['current_away_elo'] = current_away_elo_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150f670",
   "metadata": {},
   "source": [
    "streak (possitive effect on pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "48b036fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and update the winning streak for each team\n",
    "def calculate_streak(row, team_streaks):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Store the current winning streak before updating it, so it appears for the next matchday\n",
    "    row['home_team_streak'] = team_streaks[home_team]\n",
    "    row['away_team_streak'] = team_streaks[away_team]\n",
    "    \n",
    "    # Update the winning streak based on the result of the current matchday\n",
    "    if row['FTR'] == 'H':  # Home team wins\n",
    "        team_streaks[home_team] += 1  # Increment home team winning streak\n",
    "        team_streaks[away_team] = 0   # Reset away team streak\n",
    "    elif row['FTR'] == 'A':  # Away team wins\n",
    "        team_streaks[away_team] += 1  # Increment away team winning streak\n",
    "        team_streaks[home_team] = 0   # Reset home team streak\n",
    "    else:  # Draw\n",
    "        team_streaks[home_team] = 0   # Reset both streaks\n",
    "        team_streaks[away_team] = 0\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8afe4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to track the winning streaks for each team\n",
    "team_streaks_df1 = defaultdict(int)\n",
    "\n",
    "# Wende die Funktion auf den ersten DataFrame an\n",
    "match_stats = match_stats.apply(lambda row: calculate_streak(row, team_streaks_df1), axis=1)\n",
    "\n",
    "# FÃ¼r den zweiten DataFrame ein neues Dictionary verwenden\n",
    "team_streaks_df2 = defaultdict(int)\n",
    "test_data = test_data.apply(lambda row: calculate_streak(row, team_streaks_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ff57a",
   "metadata": {},
   "source": [
    "goals last 5 matches (negative effect on streak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "adb5eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the total goals scored in the last 5 matches\n",
    "def calculate_last_5_goals(row, team_goals_history):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Calculate the total goals for the last 5 matches\n",
    "    row['home_last_5_goals'] = sum(team_goals_history[home_team])\n",
    "    row['away_last_5_goals'] = sum(team_goals_history[away_team])\n",
    "    \n",
    "    # Update the goals history for the current match\n",
    "    team_goals_history[home_team].append(row['FTHG'])  # Full Time Home Goals\n",
    "    team_goals_history[away_team].append(row['FTAG'])  # Full Time Away Goals\n",
    "    \n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b61fa493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to track the last 5 goals for each team for the first DataFrame\n",
    "team_goals_history_df1 = defaultdict(lambda: deque(maxlen=5))\n",
    "\n",
    "# Apply the function to the first DataFrame\n",
    "match_stats = match_stats.apply(lambda row: calculate_last_5_goals(row, team_goals_history_df1), axis=1)\n",
    "\n",
    "# For the second DataFrame, use a new dictionary\n",
    "team_goals_history_df2 = defaultdict(lambda: deque(maxlen=5))\n",
    "test_data = test_data.apply(lambda row: calculate_last_5_goals(row, team_goals_history_df2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "23a157c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creats a Excel Sheet as a output\n",
    "new= match_stats[['home_team','away_team','FTHG','FTAG','HTHG','HTAG','HST' ,'AST','HC', 'AC', 'home_team_matchday', 'away_team_matchday', 'home_last_5_goals', 'away_last_5_goals' ]]\n",
    "new.to_excel('stats_mit_Features.xlsx', index=False)\n",
    "\n",
    "new= test_data[['home_team','away_team','FTHG','FTAG','HTHG','HTAG','HST' ,'AST','HC', 'AC','home_team_matchday', 'away_team_matchday', 'home_last_5_goals', 'away_last_5_goals']]\n",
    "new.to_excel('stats_mit_Features_test.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc4bf7",
   "metadata": {},
   "source": [
    " # Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2dedc013",
   "metadata": {},
   "outputs": [],
   "source": [
    " prediction_df = match_stats[['current_home_elo', 'current_away_elo', 'FTR',\n",
    "                            'home_last_5_corners_shot', 'away_last_5_corners_shot', \n",
    "                             'home_value', 'away_value','home_last_5_goal_diff', 'away_last_5_goal_diff',\n",
    "                             'home_cumulative_points', 'away_cumulative_points',\n",
    "                            'home_last_5_half_time_goals', 'away_last_5_half_time_goals',\n",
    "                            'home_team_matchday', 'away_team_matchday', 'home_team_streak', 'away_team_streak'\n",
    "                             ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7d913307",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_data[[ 'current_home_elo', 'current_away_elo', 'FTR', \n",
    "                     'home_last_5_corners_shot', 'away_last_5_corners_shot', \n",
    "                     'home_value', 'away_value', 'home_last_5_goal_diff', 'away_last_5_goal_diff',   \n",
    "                     'home_cumulative_points', 'away_cumulative_points', \n",
    "                    'home_last_5_half_time_goals', 'away_last_5_half_time_goals',\n",
    "                    'home_team_matchday', 'away_team_matchday', 'home_team_streak', 'away_team_streak'\n",
    "                    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "58ee6554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {0: 'A', 1: 'D', 2: 'H'}\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "#Test/ Train split\n",
    "y_train = le.fit_transform(prediction_df['FTR'])\n",
    "X_train = prediction_df.drop(columns=['FTR'])   \n",
    "y_test = le.fit_transform(test_df['FTR'])\n",
    "X_test = test_df.drop(columns=['FTR'])  \n",
    "\n",
    "label_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "print(\"Label mapping:\", label_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d534f73",
   "metadata": {},
   "source": [
    "## Implementing Random Forest + Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f1738bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 1: Accuracy on Testdata = 0.22\n",
      "\n",
      "Detailed Results for Gameday 1\n",
      "   Predicted  Actual\n",
      "0          0       1\n",
      "1          0       1\n",
      "2          1       2\n",
      "3          0       1\n",
      "4          0       2\n",
      "5          0       0\n",
      "6          2       2\n",
      "7          0       2\n",
      "8          0       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 2: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 3: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 4: Accuracy on Testdata = 0.33\n",
      "\n",
      "Detailed Results for Gameday 4\n",
      "    Predicted  Actual\n",
      "27          1       0\n",
      "28          2       1\n",
      "29          0       0\n",
      "30          2       1\n",
      "31          2       0\n",
      "32          0       0\n",
      "33          1       1\n",
      "34          2       0\n",
      "35          1       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 5: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 6: Accuracy on Testdata = 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 7: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 8: Accuracy on Testdata = 0.44\n",
      "\n",
      "Detailed Results for Gameday 8\n",
      "    Predicted  Actual\n",
      "63          1       2\n",
      "64          2       2\n",
      "65          1       0\n",
      "66          1       0\n",
      "67          1       2\n",
      "68          2       1\n",
      "69          1       1\n",
      "70          0       0\n",
      "71          1       1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 9: Accuracy on Testdata = 0.33\n",
      "\n",
      "Detailed Results for Gameday 9\n",
      "    Predicted  Actual\n",
      "72          1       2\n",
      "73          1       0\n",
      "74          2       2\n",
      "75          0       0\n",
      "76          2       2\n",
      "77          1       2\n",
      "78          0       1\n",
      "79          0       1\n",
      "80          1       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 10: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 11: Accuracy on Testdata = 0.44\n",
      "\n",
      "Detailed Results for Gameday 11\n",
      "    Predicted  Actual\n",
      "90          1       1\n",
      "91          1       2\n",
      "92          2       2\n",
      "93          2       0\n",
      "94          1       2\n",
      "95          0       2\n",
      "96          0       1\n",
      "97          1       1\n",
      "98          0       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 12: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 13: Accuracy on Testdata = 0.44\n",
      "\n",
      "Detailed Results for Gameday 13\n",
      "     Predicted  Actual\n",
      "108          0       2\n",
      "109          1       2\n",
      "110          0       0\n",
      "111          1       2\n",
      "112          0       1\n",
      "113          0       0\n",
      "114          2       2\n",
      "115          1       2\n",
      "116          0       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 14: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 15: Accuracy on Testdata = 0.44\n",
      "\n",
      "Detailed Results for Gameday 15\n",
      "     Predicted  Actual\n",
      "126          1       0\n",
      "127          2       2\n",
      "128          0       1\n",
      "129          2       0\n",
      "130          1       2\n",
      "131          2       2\n",
      "132          0       0\n",
      "133          0       2\n",
      "134          2       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 16: Accuracy on Testdata = 0.44\n",
      "\n",
      "Detailed Results for Gameday 16\n",
      "     Predicted  Actual\n",
      "135          0       0\n",
      "136          2       0\n",
      "137          0       2\n",
      "138          2       2\n",
      "139          0       0\n",
      "140          2       1\n",
      "141          2       1\n",
      "142          2       1\n",
      "143          2       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 17: Accuracy on Testdata = 0.33\n",
      "\n",
      "Detailed Results for Gameday 17\n",
      "     Predicted  Actual\n",
      "144          2       2\n",
      "145          2       0\n",
      "146          2       2\n",
      "147          0       1\n",
      "148          2       1\n",
      "149          2       0\n",
      "150          0       2\n",
      "151          2       2\n",
      "152          1       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 18: Accuracy on Testdata = 0.22\n",
      "\n",
      "Detailed Results for Gameday 18\n",
      "     Predicted  Actual\n",
      "153          2       0\n",
      "154          2       1\n",
      "155          0       1\n",
      "156          2       2\n",
      "157          2       1\n",
      "158          2       2\n",
      "159          2       0\n",
      "160          1       0\n",
      "161          0       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 19: Accuracy on Testdata = 0.44\n",
      "\n",
      "Detailed Results for Gameday 19\n",
      "     Predicted  Actual\n",
      "162          2       2\n",
      "163          0       1\n",
      "164          0       0\n",
      "165          1       0\n",
      "166          2       2\n",
      "167          2       2\n",
      "168          1       0\n",
      "169          2       1\n",
      "170          2       1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 20: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 21: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 22: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 23: Accuracy on Testdata = 0.33\n",
      "\n",
      "Detailed Results for Gameday 23\n",
      "     Predicted  Actual\n",
      "198          0       2\n",
      "199          2       0\n",
      "200          1       0\n",
      "201          2       1\n",
      "202          1       2\n",
      "203          2       2\n",
      "204          2       2\n",
      "205          2       2\n",
      "206          2       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 24: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 25: Accuracy on Testdata = 0.33\n",
      "\n",
      "Detailed Results for Gameday 25\n",
      "     Predicted  Actual\n",
      "216          2       0\n",
      "217          0       0\n",
      "218          2       2\n",
      "219          2       1\n",
      "220          2       1\n",
      "221          2       2\n",
      "222          0       2\n",
      "223          2       0\n",
      "224          2       1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 26: Accuracy on Testdata = 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 27: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 28: Accuracy on Testdata = 0.44\n",
      "\n",
      "Detailed Results for Gameday 28\n",
      "     Predicted  Actual\n",
      "243          0       0\n",
      "244          2       1\n",
      "245          2       1\n",
      "246          2       2\n",
      "247          2       0\n",
      "248          2       0\n",
      "249          2       2\n",
      "250          2       1\n",
      "251          2       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 29: Accuracy on Testdata = 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 30: Accuracy on Testdata = 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 31: Accuracy on Testdata = 0.44\n",
      "\n",
      "Detailed Results for Gameday 31\n",
      "     Predicted  Actual\n",
      "270          2       2\n",
      "271          2       1\n",
      "272          2       1\n",
      "273          2       2\n",
      "274          0       0\n",
      "275          2       0\n",
      "276          2       2\n",
      "277          2       0\n",
      "278          0       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 32: Accuracy on Testdata = 0.33\n",
      "\n",
      "Detailed Results for Gameday 32\n",
      "     Predicted  Actual\n",
      "279          2       1\n",
      "280          1       1\n",
      "281          0       0\n",
      "282          0       2\n",
      "283          2       0\n",
      "284          2       1\n",
      "285          2       0\n",
      "286          0       2\n",
      "287          2       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gameday 33: Accuracy on Testdata = 0.56\n",
      "Gameday 34: Accuracy on Testdata = 0.44\n",
      "\n",
      "Detailed Results for Gameday 34\n",
      "     Predicted  Actual\n",
      "297          0       1\n",
      "298          2       1\n",
      "299          2       2\n",
      "300          2       2\n",
      "301          2       2\n",
      "302          2       2\n",
      "303          0       2\n",
      "304          2       1\n",
      "305          0       2\n",
      "                        Feature  Importance\n",
      "1              current_away_elo    0.097699\n",
      "4                    home_value    0.095256\n",
      "5                    away_value    0.089719\n",
      "0              current_home_elo    0.088649\n",
      "2      home_last_5_corners_shot    0.085336\n",
      "6         home_last_5_goal_diff    0.068609\n",
      "3      away_last_5_corners_shot    0.067752\n",
      "7         away_last_5_goal_diff    0.065710\n",
      "9        away_cumulative_points    0.057741\n",
      "8        home_cumulative_points    0.057046\n",
      "11  away_last_5_half_time_goals    0.045475\n",
      "10  home_last_5_half_time_goals    0.045286\n",
      "13           away_team_matchday    0.043628\n",
      "12           home_team_matchday    0.040573\n",
      "15             away_team_streak    0.025866\n",
      "14             home_team_streak    0.025654\n",
      "\n",
      "Overall Accuracy: 0.47712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, right now without optimal hyperparameter\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10, class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "gameday = 1\n",
    "accuracies = []  # Store accuracy for each matchday\n",
    "\n",
    "# Iterative training process\n",
    "while not X_test.empty:\n",
    "    \n",
    "    # Extract the first matchday (9 games)\n",
    "    X_test_batch = X_test.iloc[:9]\n",
    "    y_test_batch = y_test[:9]\n",
    "\n",
    "    # Train the model and calculate accuracy\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test_batch)\n",
    "    accuracy = accuracy_score(y_test_batch, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Gameday {gameday}: Accuracy on Testdata = {accuracy:.2f}\")\n",
    "\n",
    "    # Display predictions and actual values when accuracy is low\n",
    "    if accuracy < 0.5:\n",
    "        print(\"\\nDetailed Results for Gameday\", gameday)\n",
    "        results_df = X_test_batch.copy()\n",
    "        results_df['Predicted'] = y_pred\n",
    "        results_df['Actual'] = y_test_batch\n",
    "        print(results_df[['Predicted', 'Actual']])\n",
    "\n",
    "    # Add the 9 test data points to the training dataset\n",
    "    X_train = np.vstack([X_train, X_test_batch])\n",
    "    y_train = np.concatenate([y_train, y_test_batch])\n",
    "\n",
    "    # Remove the used test data points from X_test\n",
    "    X_test = X_test.iloc[9:]\n",
    "    y_test = y_test[9:]\n",
    "\n",
    "    gameday += 1\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = rf_model.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the importance\n",
    "print(importance_df)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = np.mean(accuracies)\n",
    "print(f\"\\nOverall Accuracy: {overall_accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a1411",
   "metadata": {},
   "source": [
    "## Hyperparameter search ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fc76c0",
   "metadata": {},
   "source": [
    "make cell under as a code cell und the upper one to a markdown cell to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75722b0",
   "metadata": {},
   "source": [
    "# Define the parameter grid for hyperparameter search\n",
    "param_dist_extended = {\n",
    "    'n_estimators': [100, 500, 1000, 1500, 2000],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': ['balanced', 'balanced_subsample', None]\n",
    "}\n",
    "# Initialize the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100,random_state=42,max_depth=10, class_weight='balanced' )\n",
    "\n",
    "# Execute RandomizedSearchCV once\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model, \n",
    "    param_distributions=param_dist_extended,\n",
    "    n_iter=50,               # Number of combinations to test\n",
    "    cv=5,                    # 5-fold cross-validation\n",
    "    scoring='accuracy',      # Scoring metric\n",
    "    n_jobs=-1,               # Use all available processors\n",
    "    random_state=42, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Apply hyperparameter search on training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Store the best parameters in a variable\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Optionally, output the best parameters and cross-validation score\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Cross-Validation Score:\", random_search.best_score_)\n",
    "\n",
    "# Define feature names based on X_train's type\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    feature_names = X_train.columns\n",
    "else:\n",
    "    feature_names = [f'Feature_{i}' for i in range(X_train.shape[1])]\n",
    "\n",
    "# Use the best parameters to create a new model\n",
    "best_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "\n",
    "# Use the best model instance for iterative training\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "gameday = 1\n",
    "accuracies = []  # List to store accuracy for each game day\n",
    "\n",
    "# Iterative process\n",
    "while len(X_test) > 0:\n",
    "    # Extract the first matchday (9 games)\n",
    "    X_test_batch = X_test[:9]\n",
    "    y_test_batch = y_test[:9]\n",
    "\n",
    "    # Train the model and calculate accuracy for the current matchday\n",
    "    best_rf_model.fit(X_train, y_train)\n",
    "    y_pred = best_rf_model.predict(X_test_batch)\n",
    "    accuracy = accuracy_score(y_test_batch, y_pred)\n",
    "    accuracies.append(accuracy)  # Store accuracy of the current matchday\n",
    "    print(f\"Gameday {gameday}: Accuracy on Testdata = {accuracy:.2f}\")\n",
    "\n",
    "    # If accuracy is low or gameday equals 4, show predictions and actual values\n",
    "    if accuracy < 0.5:\n",
    "        print(\"\\nDetailed Results for Gameday\", gameday)\n",
    "        results_df = pd.DataFrame(X_test_batch, columns=feature_names)\n",
    "        results_df['Predicted'] = y_pred\n",
    "        results_df['Actual'] = y_test_batch\n",
    "        print(results_df[['Predicted', 'Actual']])  # Show predictions and actual values\n",
    "\n",
    "    # Add the 9 test data points to the training set\n",
    "    X_train = np.vstack([X_train, X_test_batch]) \n",
    "    y_train = np.concatenate([y_train, y_test_batch])  \n",
    "\n",
    "    # Remove the used test data points from X_test\n",
    "    X_test = X_test[9:]\n",
    "    y_test = y_test[9:]\n",
    "    \n",
    "    gameday += 1\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = np.mean(accuracies)\n",
    "print(f\"\\nOverall Accuracy across all gamedays: {overall_accuracy:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
