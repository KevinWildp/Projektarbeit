{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8053a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soccerdata as sd\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, deque \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7888c9",
   "metadata": {},
   "source": [
    "# SoccerData Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "339ca350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/09/25 11:06:05] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving cached data to <span style=\"color: #800080; text-decoration-color: #800080\">/Users/kevinwildprett/soccerdata/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">MatchHistory</span> <a href=\"file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_common.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py#89\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">89</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/09/25 11:06:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving cached data to \u001b[35m/Users/kevinwildprett/soccerdata/data/\u001b[0m\u001b[95mMatchHistory\u001b[0m \u001b]8;id=640771;file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py\u001b\\\u001b[2m_common.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=782457;file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py#89\u001b\\\u001b[2m89\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving cached data to <span style=\"color: #800080; text-decoration-color: #800080\">/Users/kevinwildprett/soccerdata/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">MatchHistory</span> <a href=\"file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_common.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py#89\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">89</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving cached data to \u001b[35m/Users/kevinwildprett/soccerdata/data/\u001b[0m\u001b[95mMatchHistory\u001b[0m \u001b]8;id=740928;file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py\u001b\\\u001b[2m_common.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=841611;file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py#89\u001b\\\u001b[2m89\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Saving cached data to <span style=\"color: #800080; text-decoration-color: #800080\">/Users/kevinwildprett/soccerdata/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">FBref</span>        <a href=\"file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_common.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py#89\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">89</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving cached data to \u001b[35m/Users/kevinwildprett/soccerdata/data/\u001b[0m\u001b[95mFBref\u001b[0m        \u001b]8;id=60760;file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py\u001b\\\u001b[2m_common.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=633654;file:///Users/kevinwildprett/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/soccerdata/_common.py#89\u001b\\\u001b[2m89\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scraper class instance for  for the 2020/21 & 2021/22\n",
    "mh = sd.MatchHistory(leagues=['GER-Bundesliga'], seasons=['2020-2021'])\n",
    "mh2= sd.MatchHistory(leagues=['GER-Bundesliga'], seasons=['2021-2022'])\n",
    "fbref1 = sd.FBref(leagues=['GER-Bundesliga'], seasons=['2020-2021'])\n",
    "# Get match data of each team\n",
    "match_stats= mh.read_games()\n",
    "test_data = mh2.read_games()\n",
    "additional_train = fbref1.read_team_match_stats()\n",
    "additional_test = pd.read_csv('/Users/kevinwildprett/Desktop/Hochschule/5. Semester/Projektarbeit/Neuer Ordner/additional_train.csv', sep=';') ## !!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2257e4d2",
   "metadata": {},
   "source": [
    "# Beautiful Soup Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977eaddc",
   "metadata": {},
   "source": [
    "### Get team value for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4ca2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://www.transfermarkt.de/bundesliga/startseite/wettbewerb/L1/plus/?saison_id=2020'\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "# Header imitates browser request\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"}\n",
    "\n",
    "# HTTP-Request send\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "table = soup.find(id= 'yw1')\n",
    "teams = table.find_all('td', {'class': 'hauptlink no-border-links'})\n",
    "all_teams = [team.text.replace('\\xa0', ' ').strip() for team in teams]\n",
    "\n",
    "# Find  <tbody> \n",
    "tbody = table.find('tbody')\n",
    "\n",
    "# Find <td>-elements with class \"rechts\" in <tbody> \n",
    "if tbody:\n",
    "    gesamtwert = tbody.find_all('td', {'class': 'rechts'})\n",
    "all_values = [gesamtwert.text for i, gesamtwert in enumerate(gesamtwert) if i % 2 != 0]\n",
    "\n",
    "df_teams = pd.DataFrame({\n",
    "    'team': all_teams,\n",
    "    'total_values': all_values\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e795bd",
   "metadata": {},
   "source": [
    "### Get team value for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d3a48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://www.transfermarkt.de/bundesliga/startseite/wettbewerb/L1/saison_id/2021'\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"}\n",
    "\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "table = soup.find(id= 'yw1')\n",
    "teams = table.find_all('td', {'class': 'hauptlink no-border-links'})\n",
    "all_teams = [team.text.replace('\\xa0', ' ').strip() for team in teams]\n",
    "\n",
    "\n",
    "tbody = table.find('tbody')\n",
    "\n",
    "\n",
    "if tbody:\n",
    "    gesamtwert = tbody.find_all('td', {'class': 'rechts'})\n",
    "all_values = [gesamtwert.text for i, gesamtwert in enumerate(gesamtwert) if i % 2 != 0]\n",
    "\n",
    "df_teams2 = pd.DataFrame({\n",
    "    'team': all_teams,\n",
    "    'total_values': all_values\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ae832",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d427ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the names to the ones in the main frame\n",
    "team_mapping = {\n",
    "    'FC Bayern München': 'Bayern Munich',\n",
    "    'Borussia Dortmund': 'Dortmund',\n",
    "    'RB Leipzig': 'RB Leipzig',\n",
    "    'Bayer 04 Leverkusen': 'Leverkusen',\n",
    "    'Borussia Mönchengladbach': \"M\\'gladbach\",\n",
    "    'Eintracht Frankfurt': 'Ein Frankfurt',\n",
    "    'VfL Wolfsburg': 'Wolfsburg',\n",
    "    'Hertha BSC': 'Hertha',\n",
    "    'TSG 1899 Hoffenheim': 'Hoffenheim',\n",
    "    'VfB Stuttgart': 'Stuttgart',\n",
    "    '1.FSV Mainz 05': 'Mainz',\n",
    "    'SC Freiburg': 'Freiburg',\n",
    "    'FC Schalke 04': 'Schalke 04',\n",
    "    '1.FC Köln': 'FC Koln',\n",
    "    'SV Werder Bremen': 'Werder Bremen',\n",
    "    'FC Augsburg': 'Augsburg',\n",
    "    '1.FC Union Berlin': 'Union Berlin',\n",
    "    'Arminia Bielefeld': 'Bielefeld',\n",
    "    'SpVgg Greuther Fürth' : 'Greuther Furth',\n",
    "    'VfL Bochum' : 'Bochum'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a31ba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mapping on team value dataframe\n",
    "df_teams['team'] = df_teams['team'].replace(team_mapping)\n",
    "df_teams2['team'] = df_teams2['team'].replace(team_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f123beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'total_values' column \n",
    "df_teams['total_values'] = df_teams['total_values'].str.replace(' Mio. €', '', regex=False).str.replace(',', '.').astype(float, errors='ignore')\n",
    "df_teams2['total_values'] = df_teams2['total_values'].str.replace(' Mio. €', '', regex=False).str.replace(',', '.').astype(float, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf280f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MultiIndex into regular one\n",
    "match_stats = match_stats.reset_index()\n",
    "match_stats.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_data = test_data.reset_index()\n",
    "test_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566342c",
   "metadata": {},
   "source": [
    "### Add team value to train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad017581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge für die home_market_value-Spalte\n",
    "match_stats = pd.merge(match_stats,  df_teams[['team', 'total_values']], left_on='home_team', right_on='team').rename(columns={'total_values': 'home_value'})\n",
    "match_stats = match_stats.drop(columns=['team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b68da4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge für die away_market_value-Spalte\n",
    "match_stats = pd.merge(match_stats,  df_teams[['team', 'total_values']], left_on='away_team', right_on='team').rename(columns={'total_values': 'away_value'})\n",
    "match_stats = match_stats.drop(columns=['team'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7eaa2",
   "metadata": {},
   "source": [
    "### Add team value to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ceab95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge für die home_market_value-Spalte\n",
    "test_data = pd.merge(test_data,  df_teams2[['team', 'total_values']], left_on='home_team', right_on='team').rename(columns={'total_values': 'home_value'})\n",
    "test_data = test_data.drop(columns=['team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cbbe4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge für die away_market_value-Spalte\n",
    "test_data = pd.merge(test_data,  df_teams2[['team', 'total_values']], left_on='away_team', right_on='team').rename(columns={'total_values': 'away_value'})\n",
    "test_data = test_data.drop(columns=['team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f6e5498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_stats = match_stats.sort_values(by='date').reset_index(drop=True)\n",
    "test_data = test_data.sort_values(by='date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c6ee9",
   "metadata": {},
   "source": [
    "### Additional dataframe (Fbref) preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ff4bb98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill nan value with value above\n",
    "additional_test['team'] = additional_test['team'].fillna(method='ffill')\n",
    "\n",
    "# Fill the xGoals with 0\n",
    "additional_test['xG'] = additional_test['xG'].fillna(0)\n",
    "additional_test['xGA'] = additional_test['xGA'].fillna(0)\n",
    "\n",
    "additional_train['xG'] = additional_train['xG'].fillna(0)\n",
    "additional_train['xGA'] = additional_train['xGA'].fillna(0)\n",
    "\n",
    "additional_test['xG'] = additional_test['xG'].str.replace(',', '.', regex=False)\n",
    "additional_test['xGA'] = additional_test['xGA'].str.replace(',', '.', regex=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6a15e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MultiIndex into regular one\n",
    "additional_test = additional_test.reset_index()\n",
    "additional_test.reset_index(drop=False, inplace=True)\n",
    "\n",
    "additional_train = additional_train.reset_index()\n",
    "additional_train.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2bda98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up additional data for merging\n",
    "additional_train = additional_train.sort_values(by='date')\n",
    "additional_test = additional_test.sort_values(by='date')\n",
    "# Keep olny matchdays rows\n",
    "additional_train = additional_train[additional_train['round'].str.startswith('Matchweek', na=False)]\n",
    "additional_test = additional_test[additional_test['round'].str.startswith('Matchweek', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee303169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the additional dataframe onto the main ones\n",
    "team_mapping = {\n",
    "    'Arminia': 'Bielefeld',\n",
    "    'Augsburg': 'Augsburg',\n",
    "    'Bayern Munich': 'Bayern Munich',\n",
    "    'Dortmund': 'Dortmund',\n",
    "    'Eint Frankfurt': 'Ein Frankfurt',\n",
    "    'Freiburg': 'Freiburg',\n",
    "    'Gladbach': \"M\\'gladbach\",\n",
    "    'Hertha BSC': 'Hertha',\n",
    "    'Hoffenheim': 'Hoffenheim',\n",
    "    'Köln': 'FC Koln',\n",
    "    'Leverkusen': 'Leverkusen',\n",
    "    'Mainz 05': 'Mainz',\n",
    "    'RB Leipzig': 'RB Leipzig',\n",
    "    'Schalke 04': 'Schalke 04',\n",
    "    'Stuttgart': 'Stuttgart',\n",
    "    'Union Berlin': 'Union Berlin',\n",
    "    'Werder Bremen': 'Werder Bremen',\n",
    "    'Wolfsburg': 'Wolfsburg',\n",
    "    'Greuther Fürth': 'Greuther Furth' \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4719d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_replace = ['team', 'opponent']\n",
    "\n",
    "# Use mapping\n",
    "additional_train[columns_to_replace] = additional_train[columns_to_replace].replace(team_mapping)\n",
    "additional_test[columns_to_replace] = additional_test[columns_to_replace].replace(team_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6f7d2",
   "metadata": {},
   "source": [
    "### Merge expected goals to train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d190ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For home_team column\n",
    "match_stats = pd.merge(\n",
    "    match_stats,\n",
    "    additional_train[['team', 'opponent', 'xG']],\n",
    "    left_on=['home_team', 'away_team'],\n",
    "    right_on=['team', 'opponent'],\n",
    "    how='left'\n",
    "   \n",
    ")\n",
    "match_stats = match_stats.drop(columns=['team', 'opponent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9276df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#match_stats = match_stats.drop_duplicates(subset=['home_team', 'away_team'])\n",
    "#print(match_stats.duplicated(subset=['home_team', 'away_team']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e88bd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For away_team\n",
    "\n",
    "match_stats = pd.merge(\n",
    "    match_stats,\n",
    "    additional_train[['team', 'opponent', 'xGA']],\n",
    "    left_on=['home_team', 'away_team'],  \n",
    "    right_on=['team', 'opponent'],      \n",
    "    how='left'\n",
    ")\n",
    "match_stats = match_stats.drop(columns=['team', 'opponent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5a0d6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#match_stats = match_stats.drop_duplicates(subset=['home_team', 'away_team'])\n",
    "#print(match_stats.duplicated(subset=['home_team', 'away_team']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5b0fa87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#match_stats.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b91bf4",
   "metadata": {},
   "source": [
    "### Merge expected goals to test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89d39301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For home_team\n",
    "test_data = pd.merge(\n",
    "    test_data,\n",
    "    additional_test[['team', 'opponent', 'xG']],\n",
    "    left_on=['home_team', 'away_team'],\n",
    "    right_on=['team', 'opponent'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "test_data = test_data.drop(columns=['team', 'opponent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "db7035d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For away_team\n",
    "\n",
    "test_data = pd.merge(\n",
    "    test_data,\n",
    "    additional_test[['team', 'opponent', 'xGA']],\n",
    "    left_on=['home_team', 'away_team'],  \n",
    "    right_on=['team', 'opponent'],      \n",
    "    how='left'\n",
    ")\n",
    "test_data = test_data.drop(columns=['team', 'opponent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ceae3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = test_data.drop_duplicates(subset=['home_team', 'away_team'])\n",
    "#print(test_data.duplicated(subset=['home_team', 'away_team']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dfedc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a5fc4f",
   "metadata": {},
   "source": [
    "# Feature-Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1449be",
   "metadata": {},
   "source": [
    "Matchdays (possitive impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aff0b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate matchdays for each team\n",
    "def update_matchday(row,team_matchday_counts):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Increment matchday count for home and away teams\n",
    "    team_matchday_counts[home_team] += 1\n",
    "    team_matchday_counts[away_team] += 1\n",
    "    \n",
    "    # Assign matchday counts to the row\n",
    "    row['home_team_matchday'] = team_matchday_counts[home_team]\n",
    "    row['away_team_matchday'] = team_matchday_counts[away_team]\n",
    "    \n",
    "    return row\n",
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_matchday_counts_df1 = defaultdict(int)\n",
    "match_stats = match_stats.apply(lambda row: update_matchday(row, team_matchday_counts_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_matchday_counts_df2 = defaultdict(int)\n",
    "test_data = test_data.apply(lambda row: update_matchday(row, team_matchday_counts_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749c3884",
   "metadata": {},
   "source": [
    "Cumulative Points (possitive impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "730d7f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update cumulative points for each team\n",
    "def update_cumulative_points(row, team_points):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    home_matchday = row['home_team_matchday']\n",
    "    away_matchday = row['away_team_matchday']\n",
    "    \n",
    "    # Initialize cumulative points as 0 for the first matchday\n",
    "    if home_matchday == 1:\n",
    "        row['home_cumulative_points'] = 0\n",
    "    else:\n",
    "        row['home_cumulative_points'] = team_points[home_team]\n",
    "    \n",
    "    if away_matchday == 1:\n",
    "        row['away_cumulative_points'] = 0\n",
    "    else:\n",
    "        row['away_cumulative_points'] = team_points[away_team]\n",
    "    \n",
    "    # Update points based on match result (add to history after setting current cumulative points)\n",
    "    if row['FTR'] == 'H':  # Home team wins\n",
    "        team_points[home_team] += 3  # 3 points for home team\n",
    "        team_points[away_team] += 0  # 0 points for away team\n",
    "    elif row['FTR'] == 'A':  # Away team wins\n",
    "        team_points[home_team] += 0  # 0 points for home team\n",
    "        team_points[away_team] += 3  # 3 points for away team\n",
    "    else:  # Draw\n",
    "        team_points[home_team] += 1  # 1 point for home team\n",
    "        team_points[away_team] += 1  # 1 point for away team\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "333143f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_points_df1 = defaultdict(int)\n",
    "match_stats = match_stats.apply(lambda row: update_cumulative_points(row, team_points_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_points_df2 = defaultdict(int)\n",
    "test_data = test_data.apply(lambda row: update_cumulative_points(row, team_points_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc1b8",
   "metadata": {},
   "source": [
    "Wins in last 5 matchdays (negative impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eb498ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the last 5 match history and count wins\n",
    "def update_last_5_wins(row, team_last_5_results):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Calculate the number of wins in the last 5 matches or fewer if not enough matches have been played\n",
    "    row['home_last_5_wins'] = sum(team_last_5_results[home_team])\n",
    "    row['away_last_5_wins'] = sum(team_last_5_results[away_team])\n",
    "    \n",
    "    # Add current match result to history (after calculation)\n",
    "    if row['FTR'] == 'H':  # Home team wins\n",
    "        team_last_5_results[home_team].append(1)\n",
    "        team_last_5_results[away_team].append(0)\n",
    "    elif row['FTR'] == 'A':  # Away team wins\n",
    "        team_last_5_results[home_team].append(0)\n",
    "        team_last_5_results[away_team].append(1)\n",
    "    else:  # Draw\n",
    "        team_last_5_results[home_team].append(0)\n",
    "        team_last_5_results[away_team].append(0)\n",
    "    \n",
    "    return row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "30a36ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_last_5_results_df1 = defaultdict(lambda: deque(maxlen=5))\n",
    "match_stats = match_stats.apply(lambda row: update_last_5_wins(row, team_last_5_results_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_last_5_results_df2 = defaultdict(lambda: deque(maxlen=5))\n",
    "test_data = test_data.apply(lambda row: update_last_5_wins(row, team_last_5_results_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c49388f",
   "metadata": {},
   "source": [
    "Shots on Goal (negative impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7724f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the number of shots on target for each team in the last 5 matches\n",
    "def update_last_5_shots(row, team_last_5_shots):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Calculate the total shots on target in the last 5 matches or fewer if not enough matches have been played\n",
    "    row['home_last_5_shots'] = sum(team_last_5_shots[home_team])\n",
    "    row['away_last_5_shots'] = sum(team_last_5_shots[away_team])\n",
    "    \n",
    "    # Add current match shots on target to history\n",
    "    team_last_5_shots[home_team].append(row['HST'])  # Home shots on target\n",
    "    team_last_5_shots[away_team].append(row['AST'])  # Away shots on target\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8fc06c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_last_5_shots_df1 = defaultdict(lambda: deque(maxlen=5))\n",
    "match_stats = match_stats.apply(lambda row: update_last_5_shots(row, team_last_5_shots_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_last_5_shots_df2 = defaultdict(lambda: deque(maxlen=5))\n",
    "test_data = test_data.apply(lambda row: update_last_5_shots(row, team_last_5_shots_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612013b0",
   "metadata": {},
   "source": [
    "Goaldifference (possitive impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1a7be4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the goal difference for each team in the last 5 matches\n",
    "def update_last_5_goal_diff(row, team_last_5_goal_diff):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Calculate the current match goal difference\n",
    "    home_goal_diff = row['FTHG'] - row['FTAG']\n",
    "    away_goal_diff = -home_goal_diff  # Invert for the away team\n",
    "\n",
    "    # Calculate the total goal difference in the last 5 matches or fewer if not enough matches have been played\n",
    "    row['home_last_5_goal_diff'] = sum(team_last_5_goal_diff[home_team])\n",
    "    row['away_last_5_goal_diff'] = sum(team_last_5_goal_diff[away_team])\n",
    "    \n",
    "    # Add current match goal difference to history\n",
    "    team_last_5_goal_diff[home_team].append(home_goal_diff)\n",
    "    team_last_5_goal_diff[away_team].append(away_goal_diff)\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e6e6ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_last_5_goal_diff_df1 = defaultdict(lambda: deque(maxlen=5))\n",
    "match_stats = match_stats.apply(lambda row: update_last_5_goal_diff(row, team_last_5_goal_diff_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_last_5_goal_diff_df2 = defaultdict(lambda: deque(maxlen=5))\n",
    "test_data = test_data.apply(lambda row: update_last_5_goal_diff(row, team_last_5_goal_diff_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe61d8",
   "metadata": {},
   "source": [
    "Amount halftime goals (possitive impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fdf37464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and update the sum of half-time goals for the last 5 matches for each team\n",
    "def calculate_last_5_half_time_goals(row, team_last_5_half_time_goals):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Calculate the sum of half-time goals in the last 5 matches or fewer if not enough matches have been played\n",
    "    row['home_last_5_half_time_goals'] = sum(team_last_5_half_time_goals[home_team])\n",
    "    row['away_last_5_half_time_goals'] = sum(team_last_5_half_time_goals[away_team])\n",
    "    \n",
    "    # Add the current match half-time goals to history\n",
    "    team_last_5_half_time_goals[home_team].append(row['HTHG'])  # Home half-time goals\n",
    "    team_last_5_half_time_goals[away_team].append(row['HTAG'])  # Away half-time goals\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "632ab0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_last_5_half_time_goals_df1 = defaultdict(lambda: deque(maxlen=5))\n",
    "match_stats = match_stats.apply(lambda row: calculate_last_5_half_time_goals(row, team_last_5_half_time_goals_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_last_5_half_time_goals_df2 = defaultdict(lambda: deque(maxlen=5))\n",
    "test_data = test_data.apply(lambda row: calculate_last_5_half_time_goals(row, team_last_5_half_time_goals_df2), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e8e0ef",
   "metadata": {},
   "source": [
    "Corner shots (possitive impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7ec586c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and update the sum of shot corners for the last 5 matches for each team\n",
    "def calculate_last_5_corners_shot(row, team_last_5_corners_shot):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Calculate the sum of Corners in the last 5 matches or fewer if not enough matches have been played\n",
    "    row['home_last_5_half_corners_shot'] = sum(team_last_5_corners_shot[home_team])\n",
    "    row['away_last_5_half_corners_shot'] = sum(team_last_5_corners_shot[away_team])\n",
    "    \n",
    "    # Add the current match corners to history\n",
    "    team_last_5_corners_shot[home_team].append(row['HC'])  # Home Corners\n",
    "    team_last_5_corners_shot[away_team].append(row['AC'])  # Away Corners\n",
    "    \n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "699c688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the first DataFrame with a separate dictionary\n",
    "team_last_5_corners_shot_df1 = defaultdict(lambda: deque(maxlen=5))\n",
    "match_stats = match_stats.apply(lambda row: calculate_last_5_corners_shot(row, team_last_5_corners_shot_df1), axis=1)\n",
    "\n",
    "# Apply the function to the second DataFrame with a new dictionary\n",
    "team_last_5_corners_shot_df2 = defaultdict(lambda: deque(maxlen=5))\n",
    "test_data = test_data.apply(lambda row: calculate_last_5_corners_shot(row, team_last_5_corners_shot_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26778443",
   "metadata": {},
   "source": [
    "ELO-Ratings (possitive impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "46f3e1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/wh82d8z12pjcn_v99zhyg1t80000gn/T/ipykernel_30386/750708775.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  match_stats['current_home_elo'] = current_home_elo_list\n",
      "/var/folders/n_/wh82d8z12pjcn_v99zhyg1t80000gn/T/ipykernel_30386/750708775.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  match_stats['current_away_elo'] = current_away_elo_list\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to keep track of current Elo ratings for each team\n",
    "# Reset Elo ratings and ensure initial value is 1500 for all teams\n",
    "# Re-initialize Elo calculation to ensure correct data\n",
    "team_elo = defaultdict(lambda: 1500)\n",
    "K=32\n",
    "\n",
    "# Lists to store Elo ratings for current matchdays\n",
    "current_home_elo_list = []\n",
    "current_away_elo_list = []\n",
    "\n",
    "# Iterate over each match to calculate Elo ratings correctly\n",
    "for index, row in match_stats.iterrows():\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "\n",
    "    # Get the current Elo ratings from the dictionary\n",
    "    current_home_elo = team_elo[home_team]\n",
    "    current_away_elo = team_elo[away_team]\n",
    "\n",
    "    # Append the current Elo ratings to the lists\n",
    "    current_home_elo_list.append(current_home_elo)\n",
    "    current_away_elo_list.append(current_away_elo)\n",
    "\n",
    "    # Calculate expected outcomes\n",
    "    expected_home = 1 / (1 + 10 ** ((current_away_elo - current_home_elo) / 400))\n",
    "    expected_away = 1 / (1 + 10 ** ((current_home_elo - current_away_elo) / 400))\n",
    "\n",
    "    # Determine actual match outcome\n",
    "    if row['FTHG'] > row['FTAG']:  # Home win\n",
    "        actual_home = 1\n",
    "        actual_away = 0\n",
    "    elif row['FTHG'] < row['FTAG']:  # Away win\n",
    "        actual_home = 0\n",
    "        actual_away = 1\n",
    "    else:  # Draw\n",
    "        actual_home = 0.5\n",
    "        actual_away = 0.5\n",
    "\n",
    "    # Update Elo ratings using the K factor\n",
    "    new_home_elo = current_home_elo + K * (actual_home - expected_home)\n",
    "    new_away_elo = current_away_elo + K * (actual_away - expected_away)\n",
    "\n",
    "    # Update the dictionary with the new Elo ratings for the next match\n",
    "    team_elo[home_team] = new_home_elo\n",
    "    team_elo[away_team] = new_away_elo\n",
    "\n",
    "# Add the current Elo ratings to the DataFrame\n",
    "match_stats['current_home_elo'] = current_home_elo_list\n",
    "match_stats['current_away_elo'] = current_away_elo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "30288501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/wh82d8z12pjcn_v99zhyg1t80000gn/T/ipykernel_30386/3069934253.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data['current_home_elo'] = current_home_elo_list\n",
      "/var/folders/n_/wh82d8z12pjcn_v99zhyg1t80000gn/T/ipykernel_30386/3069934253.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data['current_away_elo'] = current_away_elo_list\n"
     ]
    }
   ],
   "source": [
    "# 4 test data\n",
    "# Dictionary to keep track of current Elo ratings for each team\n",
    "# Reset Elo ratings and ensure initial value is 1500 for all teams\n",
    "# Re-initialize Elo calculation to ensure correct data\n",
    "team_elo = defaultdict(lambda: 1500)\n",
    "K=32\n",
    "\n",
    "# Lists to store Elo ratings for current matchdays\n",
    "current_home_elo_list = []\n",
    "current_away_elo_list = []\n",
    "\n",
    "# Iterate over each match to calculate Elo ratings correctly\n",
    "for index, row in test_data.iterrows():\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "\n",
    "    # Get the current Elo ratings from the dictionary\n",
    "    current_home_elo = team_elo[home_team]\n",
    "    current_away_elo = team_elo[away_team]\n",
    "\n",
    "    # Append the current Elo ratings to the lists\n",
    "    current_home_elo_list.append(current_home_elo)\n",
    "    current_away_elo_list.append(current_away_elo)\n",
    "\n",
    "    # Calculate expected outcomes\n",
    "    expected_home = 1 / (1 + 10 ** ((current_away_elo - current_home_elo) / 400))\n",
    "    expected_away = 1 / (1 + 10 ** ((current_home_elo - current_away_elo) / 400))\n",
    "\n",
    "    # Determine actual match outcome\n",
    "    if row['FTHG'] > row['FTAG']:  # Home win\n",
    "        actual_home = 1\n",
    "        actual_away = 0\n",
    "    elif row['FTHG'] < row['FTAG']:  # Away win\n",
    "        actual_home = 0\n",
    "        actual_away = 1\n",
    "    else:  # Draw\n",
    "        actual_home = 0.5\n",
    "        actual_away = 0.5\n",
    "\n",
    "    # Update Elo ratings using the K factor\n",
    "    new_home_elo = current_home_elo + K * (actual_home - expected_home)\n",
    "    new_away_elo = current_away_elo + K * (actual_away - expected_away)\n",
    "\n",
    "    # Update the dictionary with the new Elo ratings for the next match\n",
    "    team_elo[home_team] = new_home_elo\n",
    "    team_elo[away_team] = new_away_elo\n",
    "\n",
    "# Add the current Elo ratings to the DataFrame\n",
    "test_data['current_home_elo'] = current_home_elo_list\n",
    "test_data['current_away_elo'] = current_away_elo_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150f670",
   "metadata": {},
   "source": [
    "streak (possitive impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "48b036fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and update the winning streak for each team\n",
    "def calculate_streak(row, team_streaks):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Store the current winning streak before updating it, so it appears for the next matchday\n",
    "    row['home_team_streak'] = team_streaks[home_team]\n",
    "    row['away_team_streak'] = team_streaks[away_team]\n",
    "    \n",
    "    # Update the winning streak based on the result of the current matchday\n",
    "    if row['FTR'] == 'H':  # Home team wins\n",
    "        team_streaks[home_team] += 1  # Increment home team winning streak\n",
    "        team_streaks[away_team] = 0   # Reset away team streak\n",
    "    elif row['FTR'] == 'A':  # Away team wins\n",
    "        team_streaks[away_team] += 1  # Increment away team winning streak\n",
    "        team_streaks[home_team] = 0   # Reset home team streak\n",
    "    else:  # Draw\n",
    "        team_streaks[home_team] = 0   # Reset both streaks\n",
    "        team_streaks[away_team] = 0\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e8afe4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to track the winning streaks for each team\n",
    "team_streaks_df1 = defaultdict(int)\n",
    "\n",
    "# Use the function on the first DataFrame \n",
    "match_stats = match_stats.apply(lambda row: calculate_streak(row, team_streaks_df1), axis=1)\n",
    "\n",
    "# Create for the second DataFrame a new Dictionary \n",
    "team_streaks_df2 = defaultdict(int)\n",
    "test_data = test_data.apply(lambda row: calculate_streak(row, team_streaks_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ff57a",
   "metadata": {},
   "source": [
    "goals last 5 matches (negative impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "adb5eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the total goals scored in the last 5 matches\n",
    "def calculate_last_5_goals(row, team_goals_history):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    \n",
    "    # Calculate the total goals for the last 5 matches\n",
    "    row['home_last_5_goals'] = sum(team_goals_history[home_team])\n",
    "    row['away_last_5_goals'] = sum(team_goals_history[away_team])\n",
    "    \n",
    "    # Update the goals history for the current match\n",
    "    team_goals_history[home_team].append(row['FTHG'])  # Full Time Home Goals\n",
    "    team_goals_history[away_team].append(row['FTAG'])  # Full Time Away Goals\n",
    "    \n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b61fa493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to track the last 5 goals for each team for the first DataFrame\n",
    "team_goals_history_df1 = defaultdict(lambda: deque(maxlen=5))\n",
    "\n",
    "# Apply the function to the first DataFrame\n",
    "match_stats = match_stats.apply(lambda row: calculate_last_5_goals(row, team_goals_history_df1), axis=1)\n",
    "\n",
    "# For the second DataFrame, use a new dictionary\n",
    "team_goals_history_df2 = defaultdict(lambda: deque(maxlen=5))\n",
    "test_data = test_data.apply(lambda row: calculate_last_5_goals(row, team_goals_history_df2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f1968",
   "metadata": {},
   "source": [
    "average xG (possitive impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "32ee36f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important, because of csv import of expected goals 2021/22\n",
    "test_data['xG'] = pd.to_numeric(test_data['xG'], errors='coerce')\n",
    "test_data['xGA'] = pd.to_numeric(test_data['xGA'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4ce0f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_xg_xga(row, team_stats):\n",
    "    # Hometeam Data\n",
    "    home_team = row['home_team']\n",
    "    home_matchday = row['home_team_matchday']\n",
    "    \n",
    "    # Awayteam Data\n",
    "    away_team = row['away_team']\n",
    "    away_matchday = row['away_team_matchday']\n",
    "    \n",
    "    # Initialise xG & matche\n",
    "    if home_team not in team_stats:\n",
    "        team_stats[home_team] = {'xG_total': 0, 'matches': 0}\n",
    "    if away_team not in team_stats:\n",
    "        team_stats[away_team] = {'xG_total': 0, 'matches': 0}\n",
    "    \n",
    "    # Average xG for the Hometeam \n",
    "    if home_matchday > 1:\n",
    "        row['home_avg_xG'] = team_stats[home_team]['xG_total'] / team_stats[home_team]['matches']\n",
    "    else:\n",
    "        row['home_avg_xG'] = 0  # Initalise 1. Day\n",
    "\n",
    "    # Average xGA for Awayteam  \n",
    "    if away_matchday > 1:\n",
    "        row['away_avg_xG'] = team_stats[away_team]['xG_total'] / team_stats[away_team]['matches']\n",
    "    else:\n",
    "        row['away_avg_xG'] = 0  # Initalise 1. Day\n",
    "    \n",
    "    # After Calculation: Add Game to Teamstatistic \n",
    "    team_stats[home_team]['xG_total'] += row['xG']\n",
    "    team_stats[home_team]['matches'] += 1\n",
    "    \n",
    "    team_stats[away_team]['xG_total'] += row['xGA']\n",
    "    team_stats[away_team]['matches'] += 1\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Initalize Team-Statistic\n",
    "team_stats = defaultdict(lambda: {'xG_sum': 0, 'matches': 0})\n",
    "team_stats2 = defaultdict(lambda: {'xG_sum': 0, 'matches': 0})\n",
    "# Use the function on the DataFrame\n",
    "match_stats = match_stats.apply(lambda row: calculate_avg_xg_xga(row, team_stats), axis=1)\n",
    "test_data = test_data.apply(lambda row: calculate_avg_xg_xga(row, team_stats2), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc4bf7",
   "metadata": {},
   "source": [
    "select Dataframes for Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2dedc013",
   "metadata": {},
   "outputs": [],
   "source": [
    " prediction_df = match_stats[['current_home_elo', 'current_away_elo', 'FTR',\n",
    "                            'home_last_5_half_corners_shot', 'away_last_5_half_corners_shot', \n",
    "                             'home_value', 'away_value','home_last_5_goal_diff', 'away_last_5_goal_diff',\n",
    "                             'home_cumulative_points', 'away_cumulative_points',\n",
    "                            'home_last_5_half_time_goals', 'away_last_5_half_time_goals',\n",
    "                            'home_team_matchday','away_team_matchday',  'home_team_streak', 'away_team_streak',\n",
    "                              'home_avg_xG', 'away_avg_xG'\n",
    "                             ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7d913307",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_data[[ 'current_home_elo', 'current_away_elo', 'FTR', \n",
    "                     'home_last_5_half_corners_shot', 'away_last_5_half_corners_shot', \n",
    "                     'home_value', 'away_value', 'home_last_5_goal_diff', 'away_last_5_goal_diff',   \n",
    "                     'home_cumulative_points', 'away_cumulative_points', \n",
    "                    'home_last_5_half_time_goals', 'away_last_5_half_time_goals',\n",
    "                    'home_team_matchday','away_team_matchday',  'home_team_streak', 'away_team_streak',\n",
    "                     'home_avg_xG', 'away_avg_xG', \n",
    "                     \n",
    "                    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "58ee6554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {0: 'A', 1: 'D', 2: 'H'}\n"
     ]
    }
   ],
   "source": [
    "# Scale Data\n",
    "le = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "# Test/ Train split\n",
    "y_train = le.fit_transform(prediction_df['FTR'])\n",
    "X_train = prediction_df.drop(columns=['FTR'])   \n",
    "y_test = le.fit_transform(test_df['FTR'])\n",
    "X_test = test_df.drop(columns=['FTR']) \n",
    "\n",
    "# Create Korrelationsmatrix \n",
    "correlation_matrix = X_train.corr()\n",
    "\n",
    "# Clone data for boxplot\n",
    "X_train_box = X_train\n",
    "\n",
    "# Skale data\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "\n",
    "label_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "print(\"Label mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d534f73",
   "metadata": {},
   "source": [
    "## Implementing Random Forest + Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ab98a51b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m rf_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate initial accuracy on the test data without modifying it\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m initial_y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m initial_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, initial_y_pred)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial Accuracy on Test Data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    863\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    868\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 599\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/schule/miniconda3/envs/ml-course/lib/python3.8/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "# Train the model on the initial training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Calculate initial accuracy on the test data without modifying it\n",
    "initial_y_pred = rf_model.predict(X_test)\n",
    "initial_accuracy = accuracy_score(y_test, initial_y_pred)\n",
    "print(f\"Initial Accuracy on Test Data: {initial_accuracy:.2f}\")\n",
    "\n",
    "gameday = 1\n",
    "accuracies = []  # List to store accuracy for each matchday\n",
    "all_game_data = []  # List to store odds and team data for each matchday\n",
    "\n",
    "# Iterative process\n",
    "while X_test.size > 0:  # Check for NumPy array or Pandas DataFrame size\n",
    "    # Extract the test data for the current matchday (9 matches)\n",
    "    X_test_batch = X_test.iloc[:9]\n",
    "    y_test_batch = y_test[:9]\n",
    "    teams_batch = test_data.iloc[:9][['home_team', 'away_team']].reset_index(drop=True)\n",
    "\n",
    "    # Train the model on the current training data\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and calculate probabilities (for Quotas)\n",
    "    y_pred = rf_model.predict(X_test_batch)\n",
    "    y_proba = rf_model.predict_proba(X_test_batch)\n",
    "\n",
    "    # Calculate and store accuracy\n",
    "    accuracy = accuracy_score(y_test_batch, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Gameday {gameday}: Accuracy on Testdata = {accuracy:.2f}\")\n",
    "\n",
    "    # Analyze each match of the current matchday\n",
    "    for i, probas in enumerate(y_proba):\n",
    "        home_team = teams_batch.iloc[i]['home_team']\n",
    "        away_team = teams_batch.iloc[i]['away_team']\n",
    "\n",
    "        # Calculate odds\n",
    "        odds = {\n",
    "            0: round(1 / probas[0], 2) if probas[0] > 0 else 'N/A',\n",
    "            1: round(1 / probas[1], 2) if probas[1] > 0 else 'N/A',\n",
    "            2: round(1 / probas[2], 2) if probas[2] > 0 else 'N/A'\n",
    "        }\n",
    "\n",
    "        # Output match information\n",
    "        print(f\"\\nMatch {i + 1}: {home_team} vs {away_team}\")\n",
    "        print(f\"Probabilities: Home Win ({probas[2]:.2f}), Draw ({probas[1]:.2f}), Away Win ({probas[0]:.2f})\")\n",
    "        print(f\"Odds: Home ({odds[2]}), Draw ({odds[1]}), Away ({odds[0]})\")\n",
    "\n",
    "        # Save matchday data\n",
    "        all_game_data.append({\n",
    "            'Gameday': gameday,\n",
    "            'HomeTeam': home_team,\n",
    "            'AwayTeam': away_team,\n",
    "            'Probabilities': probas,\n",
    "            'Classes': rf_model.classes_,\n",
    "            'HomeOdds': odds[2],\n",
    "            'AwayOdds': odds[0],\n",
    "            'DrawOdds': odds[1]\n",
    "        })\n",
    "  \n",
    "\n",
    "    # Add test data to training data\n",
    "    X_train = np.vstack([X_train, X_test_batch])\n",
    "    y_train = np.concatenate([y_train, y_test_batch])\n",
    "\n",
    "    # Remove the used test data\n",
    "    X_test = X_test.iloc[9:]\n",
    "    y_test = y_test[9:]\n",
    "    test_data = test_data.iloc[9:]\n",
    "\n",
    "    gameday += 1\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = np.mean(accuracies)\n",
    "print(f\"\\nOverall Accuracy: {overall_accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a1411",
   "metadata": {},
   "source": [
    "## Evaluation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c47296",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"\\nMatchday and Odds:\")\n",
    "for game in all_game_data:\n",
    "    print(f\"Matchday {game['Gameday']} {game['HomeTeam']} {game['HomeOdds']} : {game['AwayTeam']} {game['AwayOdds']} (Draw: {game['DrawOdds']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3f6b4a",
   "metadata": {},
   "source": [
    "## Corelation Matrix of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3201db52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
    "\n",
    "\n",
    "  \n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.xticks(fontsize=15)  \n",
    "plt.yticks(fontsize=15) \n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2320f75",
   "metadata": {},
   "source": [
    "## Accuracy over Matchdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matchday axis (x-axis) and accuracy values (y-axis)\n",
    "gamedays = list(range(1, len(accuracies) + 1))  # Matchdays (1, 2, ..., n)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(gamedays, accuracies, marker='o', linestyle='-', linewidth=2)\n",
    "\n",
    "# Add labels to the plot\n",
    "plt.title('Accuracy Trend Over Matchdays', fontsize=16)\n",
    "plt.xlabel('Matchday', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.xticks(gamedays)  # Optional: Display each matchday as a tick\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78324710",
   "metadata": {},
   "source": [
    "## Comparasion scaled vs unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04cd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.DataFrame(X_train, columns=list(X_train_box.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342cf97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current_elo = X_train_box[['current_home_elo']]\n",
    "df_scaled_current_elo = df_scaled[['current_home_elo']]\n",
    "# Prepare data (Unscaled)\n",
    "df_unscaled_melted = df_current_elo.melt(var_name='Feature', value_name='Value')\n",
    "df_unscaled_melted['Type'] = 'Unscaled'\n",
    "\n",
    "# Prepare data (Scaled)\n",
    "df_scaled_melted = df_scaled_current_elo.melt(var_name='Feature', value_name='Value')\n",
    "df_scaled_melted['Type'] = 'Scaled'\n",
    "\n",
    "# Combine data\n",
    "df_combined = pd.concat([df_unscaled_melted, df_scaled_melted])\n",
    "\n",
    "# Create boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Feature', y='Value', hue='Type', data=df_combined, palette='Set2')\n",
    "plt.title(\"Comparison of Unscaled and Scaled Home Elo\", fontsize=16)\n",
    "plt.ylabel(\"Values\", fontsize=14)\n",
    "plt.xlabel(\"Feature\", fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(\"Values Range for 'current_home_elo':\")\n",
    "print(f\"Unscaled: Min = {df_current_elo['current_home_elo'].min()}, Max = {df_current_elo['current_home_elo'].max()}\")\n",
    "print(f\"Scaled: Min = {df_scaled_current_elo['current_home_elo'].min():.2f}, Max = {df_scaled_current_elo['current_home_elo'].max():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
